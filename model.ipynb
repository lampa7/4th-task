{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e60dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb3aace4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "969305ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation\n",
    "transformer=transforms.Compose([\n",
    "    transforms.Resize((150,150)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n",
    "    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n",
    "                        [0.5,0.5,0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73b8a194",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataloader\n",
    "train_path = './train_imgs/'\n",
    "test_path = './test_imgs/'\n",
    "\n",
    "train_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n",
    "    batch_size=9, shuffle=True\n",
    ")\n",
    "test_loader=DataLoader(\n",
    "    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n",
    "    batch_size=5, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "079eea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.0', '1.0', '2.0', '3.0', '5.0', '9.0']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = sorted(os.listdir(train_path))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e510224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self,num_classes=6):\n",
    "        super(ConvNet,self).__init__()\n",
    "        #((w-f+2P)/s) +1\n",
    "        \n",
    "        #(256,3,150,150)\n",
    "        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n",
    "        #(256,12,150,150)\n",
    "        self.bn1=nn.BatchNorm2d(num_features=12)\n",
    "        self.relu1=nn.ReLU()\n",
    "        \n",
    "        self.pool=nn.MaxPool2d(kernel_size=2)\n",
    "        #(256,12,75,75)\n",
    "        \n",
    "        \n",
    "        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,20,75,75)\n",
    "        self.relu2=nn.ReLU()        \n",
    "        \n",
    "        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n",
    "        #Shape= (256,32,75,75)\n",
    "        self.bn3=nn.BatchNorm2d(num_features=32)\n",
    "        self.relu3=nn.ReLU()\n",
    "        \n",
    "        \n",
    "        self.fc=nn.Linear(in_features=75 * 75 * 32, out_features=num_classes)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #forwad pass\n",
    "        \n",
    "    def forward(self,input):\n",
    "        output = self.conv1(input)\n",
    "        output = self.bn1(output)\n",
    "        output = self.relu1(output)\n",
    "            \n",
    "        output = self.pool(output)\n",
    "            \n",
    "        output = self.conv2(output)\n",
    "        output = self.relu2(output)\n",
    "            \n",
    "        output = self.conv3(output)\n",
    "        output = self.bn3(output)\n",
    "        output = self.relu3(output)\n",
    "            \n",
    "        output=output.view(-1,32*75*75)\n",
    "            \n",
    "        output=self.fc(output)\n",
    "            \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "894d322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=ConvNet(num_classes=6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e45b0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\n",
    "loss_function=nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "450e2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7444c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating size of train and test datasets\n",
    "train_num = len(glob.glob(train_path+'/**/*.png'))\n",
    "test_num = len(glob.glob(test_path+'/**/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ea1b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "454 47\n"
     ]
    }
   ],
   "source": [
    "print(train_count,test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e48041da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Train Loss: tensor(0.1337) Train Accuracy: 0.9713656387665198 Test Accuracy: 0.46808510638297873\n",
      "Epoch: 1 Train Loss: tensor(0.0356) Train Accuracy: 0.986784140969163 Test Accuracy: 0.48936170212765956\n",
      "Epoch: 2 Train Loss: tensor(0.0184) Train Accuracy: 0.9933920704845814 Test Accuracy: 0.46808510638297873\n",
      "Epoch: 3 Train Loss: tensor(0.0100) Train Accuracy: 0.9977973568281938 Test Accuracy: 0.44680851063829785\n",
      "Epoch: 4 Train Loss: tensor(0.0645) Train Accuracy: 0.9713656387665198 Test Accuracy: 0.46808510638297873\n",
      "Epoch: 5 Train Loss: tensor(0.0432) Train Accuracy: 0.9779735682819384 Test Accuracy: 0.44680851063829785\n",
      "Epoch: 6 Train Loss: tensor(0.0549) Train Accuracy: 0.986784140969163 Test Accuracy: 0.44680851063829785\n",
      "Epoch: 7 Train Loss: tensor(0.0608) Train Accuracy: 0.973568281938326 Test Accuracy: 0.48936170212765956\n",
      "Epoch: 8 Train Loss: tensor(0.0590) Train Accuracy: 0.9757709251101322 Test Accuracy: 0.46808510638297873\n",
      "Epoch: 9 Train Loss: tensor(0.0199) Train Accuracy: 0.9933920704845814 Test Accuracy: 0.46808510638297873\n"
     ]
    }
   ],
   "source": [
    "#Model training and saving best model\n",
    "\n",
    "best_accuracy = 0.0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy = 0.0\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for i, (images,labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        # zero gradients    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs,labels)\n",
    "        \n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss += loss.cpu().data*images.size(0)\n",
    "        _,prediction =torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy += int(torch.sum(prediction == labels.data))\n",
    "        \n",
    "    train_accuracy = train_accuracy/train_count\n",
    "    train_loss = train_loss/train_count\n",
    "    \n",
    "    \n",
    "    # Evaluation on testing dataset\n",
    "    model.eval()\n",
    "    \n",
    "    test_accuracy=0.0\n",
    "    for i, (images,labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "            \n",
    "        outputs = model(images)\n",
    "        _,prediction = torch.max(outputs.data,1)\n",
    "        test_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    \n",
    "    test_accuracy = test_accuracy/test_count\n",
    "    \n",
    "    \n",
    "    print('Epoch: ' + str(epoch) + ' Train Loss: ' + str(train_loss) + ' Train Accuracy: ' + \\\n",
    "          str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n",
    "    \n",
    "    #Save the best model\n",
    "    if test_accuracy > best_accuracy:\n",
    "        torch.save(model.state_dict(),'best_checkpoint.model')\n",
    "        best_accuracy = test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8b9920",
   "metadata": {},
   "source": [
    " Here accuracy is not the best metric because of imbalanced dataset.\n",
    " \n",
    " With oversampling we can handle imbalanced classes though there's risk of overfitting.\n",
    " \n",
    " Adjusting a loss function is also a good idea (paper 'Focal Loss for Dense Object Detection', https://arxiv.org/pdf/1708.02002.pdf).\n",
    " \n",
    " Mainly, we need more data for getting good predictions. \n",
    " \n",
    " Augmentation also will increase model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce97d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
